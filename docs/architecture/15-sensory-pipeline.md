# Architecture Design: Sensory Pipeline (Epic 14)

**Version:** 1.0
**Status:** In Definition
**Author:** Winston (Architect)
**Date:** 2026-01-28

---

## 1. Introduction

Ce document d√©finit l'architecture des flux sensoriels (audition et parole) de hAIrem. L'objectif est de permettre une interaction vocale fluide, √† faible latence, int√©gr√©e au protocole H-Link.

## 2. Flux d'Audition (Ears : ASR)

Le pipeline d'audition transforme la voix de l'utilisateur en texte trait√© comme un stimulus par le Core.

### 2.1 Capture & Streaming
1. **A2UI :** Capture l'audio via l'API Web MediaRecorder (format Opus/WebM).
2. **H-Bridge :** Re√ßoit les chunks audio par WebSocket et les accumule dans un buffer m√©moire.
3. **Transcription (Whisper) :** 
   - Utilisation d'une instance **Faster-Whisper** (locale ou containeris√©e).
   - Le Bridge envoie le buffer au service de transcription une fois le silence d√©tect√© (VAD - Voice Activity Detection).
4. **H-Link :** Le texte transcrit est publi√© sur Redis avec le type `system.whisper`.

## 3. Flux de Parole (Voice : TTS & Modulation)

Le syst√®me doit √™tre agnostique vis-√†-vis des moteurs de synth√®se pour permettre l'utilisation de voix ultra-r√©alistes ou clon√©es (Luxa, ElevenLabs, Piper).

### 3.1 Abstraction Provider
1. **TTS Service :** Interface g√©n√©rique `VoiceProvider`.
2. **Voice Profiles :** Chaque agent d√©finit dans son `persona.yaml` :
   - `provider` : Le moteur √† utiliser (ex: `luxa`).
   - `voice_id` : L'identifiant de la voix de r√©f√©rence.
   - `modulation_params` : Param√®tres de ton, de vitesse et d'√©motion (injectables dynamiquement selon le sentiment de la r√©ponse).

### 3.2 Clonage & Imitation (Luxa/Advanced)
- Pour les agents n√©cessitant une identit√© vocale forte, le pipeline supporte le **Zero-Shot Voice Cloning**. 
- Un √©chantillon de 10s de la voix de r√©f√©rence est stock√© dans `agents/{id}/media/voice_ref.wav`.
- Le provider utilise cette r√©f√©rence pour g√©n√©rer chaque r√©ponse, garantissant une signature vocale unique.

### 3.2 Rendu
1. **A2UI :** Re√ßoit l'URL, pr√©charge l'audio et d√©clenche la lecture en synchronisation avec l'affichage du texte (si possible avec des marqueurs de synchronisation labiale / vis√®mes).

## 4. Latence et Optimisation

- **Local Inference :** Utilisation de mod√®les quantifi√©s (Piper GMS, Whisper Tiny/Base) pour garantir une r√©ponse en < 1s.
- **Caching :** Les r√©ponses TTS courantes ("Bonjour", "D'accord") sont cach√©es par hash SHA-256 dans Redis pour √©viter la r√©g√©n√©ration.

---
üèóÔ∏è Winston - Architecte hAIrem
