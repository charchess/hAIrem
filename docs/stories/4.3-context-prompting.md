# Story 4.3: Injection du Contexte et Prompting

**Status:** Approved
**Story:**
**As a** Developer,
**I want** to inject the agent's persona and context into every LLM request,
**so that** each agent (Renarde, Expert) behaves according to its configuration.

## Acceptance Criteria
1.  La classe `BaseAgent` assemble automatiquement le prompt système avant l'appel au LLM.
2.  Inclusion du `system_prompt` défini dans `expert.yaml`.
3.  Inclusion de l'historique récent des messages (via `AgentContext.history`).
4.  Validation : "La Renarde" répond avec son ton espiègle tandis que "l'Expert" répond de manière factuelle.

## Tasks / Subtasks
- [ ] Task 1: Prompt Assembler (AC: 1, 2)
    - [ ] Créer une méthode `_assemble_payload()` dans `BaseAgent`.
- [ ] Task 2: History Management (AC: 3)
    - [ ] Limiter l'historique aux N derniers messages pour ne pas saturer le contexte.
- [ ] Task 3: Agent Validation (AC: 4)
    - [ ] Tester les réponses croisées entre deux agents différents.

## Dev Notes
**Technical Context from Architecture:**

*   **Persona:**
    - Source: `agents/renarde/expert.yaml` et `agents/expert-domotique/expert.yaml`.

## Change Log
| Date | Version | Description | Author |
| --- | --- | --- | --- |
| 2026-01-20 | 1.0 | Initial draft | Bob (SM) |
