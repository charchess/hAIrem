# Story 8.3: Vector Embeddings & Semantic Search (RAG)

**Status:** Done
**Epic:** 8 - Persistent Memory (The Archive)

## Story
**As an** Agent (like Renarde),
**I want** to search through past interactions using semantic similarity,
**so that** I can recall relevant facts and context from previous days or sessions to provide a more consistent and personalized experience.

## Acceptance Criteria
1. [x] The `LlmClient` supports generating vector embeddings using LiteLLM.
2. [x] SurrealDB is configured with a vector index on the `messages` collection (or a specialized `memories` table).
3. [x] Every new message is automatically embedded and stored with its vector representation.
4. [x] A new tool `recall_memory(query)` is available to agents, allowing them to perform a semantic search.
5. [x] Search results are filtered by agent relevance or globally, providing the top K relevant snippets.

## Tasks / Subtasks
- [x] Backend: Vector Infrastructure (AC: #1, #2)
    - [x] Update `LlmClient` in `apps/h-core/src/infrastructure/llm.py` to include `get_embedding(text)`.
    - [x] Configure SurrealDB schema with a `vector` field (e.g., 1536 dimensions for OpenAI/Gemini) and an `MTREE` or `HNSW` index.
- [x] Backend: Automatic Indexing (AC: #3)
    - [x] Update `SurrealDbClient` to generate and store embeddings during `insert_message()`.
- [x] Agent Logic: Retrieval Tool (AC: #4, #5)
    - [x] Implement `semantic_search(query, limit=5)` in `SurrealDbClient`.
    - [x] Add the `recall_memory` tool to `BaseAgent` so all specialized agents can use it.
- [x] Testing: RAG Validation
    - [x] Create a test script that inserts specific facts, then verifies the agent can "recall" them using different wording.

## Dev Notes
- **Data Models**: Weighted Dynamic Memory (MDP) involves raw facts + subjective interpretations. [Source: architecture/4-modles-de-donnes-mmoire-subjective.md]
- **Tech Stack**: LiteLLM for both completion and embeddings. SurrealDB for vector storage. [Source: architecture/3-tech-stack.md]
- **Configuration**: Requires `EMBEDDING_MODEL` environment variable (e.g., `text-embedding-3-small` or `models/embedding-001`).
- **Index Creation**: Automatically handled in `SurrealDbClient.setup_schema()` on connection.

## Testing
- [x] Unit tests for embedding generation (mocked).
- [x] Integration tests for SurrealDB vector search queries (mocked).
- [x] Validated tool registration on `BaseAgent`.

## Change Log
| Date | Version | Description | Author |
| --- | --- | --- | --- |
| 2026-01-23 | 1.0 | Initial draft for Semantic Search / RAG | Bob (SM) |
| 2026-01-23 | 1.1 | Implementation completed and validated | James (Dev) |

## Dev Agent Record
- **Agent Model Used**: Gemini 2.0 Flash
- **Debug Log References**: [N/A]
- **Completion Notes List**:
    - [Vector embedding generation implemented via LiteLLM]
    - [SurrealDB vector search query implemented]
    - [Automatic index creation added to database setup]
    - [Recall tool registered on all agents]
- **File List**:
    - `apps/h-core/src/infrastructure/llm.py`
    - `apps/h-core/src/infrastructure/surrealdb.py`
    - `apps/h-core/src/domain/agent.py`
    - `apps/h-core/src/infrastructure/plugin_loader.py`
    - `apps/h-core/src/agents/expert_domotique.py`
    - `apps/h-core/src/main.py`
    - `tests/validate_8_3.py`

## QA Results

### Review Date: 2026-01-23

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment
Excellent implementation of the RAG pattern. The developer handled the complexity of vector indexing and cross-SDK model naming (LiteLLM prefixing) effectively. The `recall_memory` tool is a clean abstraction that empowers agents without overloading their core logic.

### Refactoring Performed
- **File**: `apps/h-core/src/infrastructure/llm.py`
  - **Change**: Added `gemini/` prefix logic for embeddings.
  - **Why**: LiteLLM required explicit provider hints for Google models.

### Compliance Check
- Coding Standards: [✓]
- Project Structure: [✓]
- Testing Strategy: [✓] (Infrastructure validated via mocked unit tests and success logs)
- All ACs Met: [✓]

### Improvements Checklist
- [x] Implemented vector embedding generation
- [x] Configured MTREE index in SurrealDB
- [x] Added `recall_memory` tool to all agents
- [ ] Monitor embedding dimension consistency across different models

### Gate Status
Gate: PASS → docs/qa/gates/8.3-semantic-search.yml
Risk profile: docs/qa/assessments/8.3-risk-20260123.md
NFR assessment: docs/qa/assessments/8.3-nfr-20260123.md
Trace matrix: docs/qa/assessments/8.3-trace-20260123.md

### Recommended Status
[✓ Ready for Done]
