# Story 14.4: Next-Gen Neural TTS (Qwen3-TTS + Dynamic LoRA)

Status: ready-for-dev

## Story

As a User,
I want the agents to speak with high-fidelity prosody and unique vocal identities using a Qwen3-TTS 0.6B GGUF model,
so that the interaction feels biologically realistic, emotional, and computationally efficient.

## Acceptance Criteria

1. **Local LLAMA Serving**: Deploy a `llama.cpp` server (GGUF Q4_K_M) dedicated to TTS, ensuring low memory footprint (~350MB).
2. **Dynamic LoRA Injection**: Implement support for dynamic voice switching using rank 16 LoRAs (~5MB per agent).
3. **Identity Alignment**: Use custom-trained LoRAs for Lisa, Electra, and Renarde to match their Character DNA.
4. **Narrative Hook**: The H-Bridge must listen to the Redis `broadcast` channel and route text to the `llama.cpp` TTS endpoint.
5. **Prosody & Intonation**: The system must leverage Qwen3's advanced audio capabilities for realistic speech (breathing, emphasis).
6. **Binary Audio Delivery**: Generated audio must be streamed back to A2UI via WebSocket binary frames.

## Tasks / Subtasks

- [x] Task 1: Setup TTS Serving Infrastructure
  - [x] Add `tts-engine` (llama.cpp server) to `docker-compose.yml`.
  - [x] Configure `tts-engine` to support dynamic LoRA loading.
- [x] Task 2: Implement Voice Orchestration in H-Bridge
  - [x] Create `apps/h-bridge/src/infrastructure/tts_qwen.py`.
  - [x] Implement LoRA selection logic based on `agent_id`.
  - [x] Handle asynchronous requests to the llama.cpp TTS API.
- [x] Task 3: LoRA Export Pipeline (Workstation side)
  - [x] Define the process for converting PEFT LoRAs to GGML/GGUF compatible format.
  - [x] Store voice LoRAs in a shared volume accessible by the `tts-engine`.
- [x] Task 4: Frontend Audio Buffer
  - [x] Update `apps/h-bridge/static/js/audio/playback.js` for real-time PCM/WAV playback.
- [x] Task 5: Integration & Latency Test
  - [x] Verify that time-to-first-byte is < 800ms for local generation.

## Dev Notes

- **Model**: Qwen3-TTS 0.6B GGUF (Quantized Q4_K_M).
- **Vocal DNA**:
    - Lisa: LoRA_Lisa_v1.bin
    - Electra: LoRA_Electra_v1.bin
    - Renarde: LoRA_Renarde_v1.bin
- **Serving**: llama.cpp with `--lora` and `--lora-base` flags or dynamic API equivalent.
- **Complexity**: High (Requires precise alignment between training and serving formats).

### Project Structure Notes

- New: `apps/h-bridge/src/infrastructure/tts_qwen.py`.
- New: `shared_assets/voices/loras/`.

### References

- [Source: PRD V4 - Pillar 2: Deep Presence]
- [Source: User Suggestion - Qwen3-TTS GGUF + LoRA Architecture]

## Dev Agent Record

### Agent Model Used

Gemini 2.0 Flash

### Debug Log References

- `QwenTTSClient` unit tests passed.
- Redis subscription for TTS events verified in `speech_orchestrator`.
- Binary WebSocket delivery logic implemented and tested.

### Completion Notes List

- Deployed `llama.cpp` server in `docker-compose.yml`.
- Created `QwenTTSClient` with dynamic LoRA mapping.
- Added `speech_orchestrator` in `main.py` for real-time narrative-to-speech conversion.
- Implemented `AudioPlayback` class in A2UI for seamless agent speech.

### File List

- `apps/h-bridge/src/infrastructure/tts_qwen.py`
- `apps/h-bridge/src/main.py`
- `docker-compose.yml`
- `apps/h-bridge/static/index.html`
- `apps/h-bridge/static/js/audio/playback.js`
- `apps/h-bridge/static/js/network.js`
- `apps/h-bridge/tests/test_tts_pipeline.py`
- `scripts/process_loras.py`

### Change Log

- 2026-02-08: Implemented Next-Gen Neural TTS using Qwen3-TTS and Dynamic LoRA.
