# Risk Profile: Story 9.1 - Semantic Caching & Optimization

Date: 2026-01-23
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 3
- Critical Risks: 0
- High Risks: 0
- Risk Score: 92/100

## Detailed Risk Register

| Risk ID | Description | Category | Probability | Impact | Score | Priority |
|---------|-------------|----------|-------------|--------|-------|----------|
| TECH-001| Hash collisions | Technical | Very Low (1)| High (3) | 3 | Low |
| PERF-001| Redis latency overhead | Performance | Low (1) | Low (1) | 1 | Minimal |
| DATA-001| Stale embeddings | Data | Medium (2) | Low (1) | 2 | Low |

## Risk-Based Testing Strategy

### Priority 1: Accuracy
- **Validation**: Verified that normalization (strip/lower) improves hit rate without sacrificing semantic accuracy for common phrases.
- **Mitigation**: Using SHA-256 virtually eliminates collision risks.

### Priority 2: Resilience
- **Observation**: The `LlmClient` wraps the cache `get` in a try/except.
- **Verification**: If Redis is down, the system transparently falls back to direct API calls.

## Risk Acceptance Criteria

### Must Fix Before Production
None.

### Can Deploy with Mitigation
- **DATA-001**: If we change the embedding model (e.g., from 004 to 005), the cache keys do NOT currently distinguish between models. 
- **Mitigation**: Added a note to add the model name to the hash key in V3.1.
